def : Pat<(int_ve_vld_vss i64:$sy, i64:$sz), (VLDrr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vld_vss (i64 simm7:$I), i64:$sz), (VLDir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vldu_vss i64:$sy, i64:$sz), (VLDUrr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vldu_vss (i64 simm7:$I), i64:$sz), (VLDUir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vldlsx_vss i64:$sy, i64:$sz), (VLDLsxrr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vldlsx_vss (i64 simm7:$I), i64:$sz), (VLDLsxir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vldlzx_vss i64:$sy, i64:$sz), (VLDLzxrr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vldlzx_vss (i64 simm7:$I), i64:$sz), (VLDLzxir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vld2d_vss i64:$sy, i64:$sz), (VLD2Drr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vld2d_vss (i64 simm7:$I), i64:$sz), (VLD2Dir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vldu2d_vss i64:$sy, i64:$sz), (VLDU2Drr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vldu2d_vss (i64 simm7:$I), i64:$sz), (VLDU2Dir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vldl2dsx_vss i64:$sy, i64:$sz), (VLDL2Dsxrr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vldl2dsx_vss (i64 simm7:$I), i64:$sz), (VLDL2Dsxir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vldl2dzx_vss i64:$sy, i64:$sz), (VLDL2Dzxrr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vldl2dzx_vss (i64 simm7:$I), i64:$sz), (VLDL2Dzxir (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vst_vss v256f64:$vx, i64:$sy, i64:$sz), (VSTrr v256f64:$vx, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vst_vss v256f64:$vx, (i64 simm7:$I), i64:$sz), (VSTir v256f64:$vx, (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vstu_vss v256f64:$vx, i64:$sy, i64:$sz), (VSTUrr v256f64:$vx, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vstu_vss v256f64:$vx, (i64 simm7:$I), i64:$sz), (VSTUir v256f64:$vx, (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vstl_vss v256f64:$vx, i64:$sy, i64:$sz), (VSTLrr v256f64:$vx, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vstl_vss v256f64:$vx, (i64 simm7:$I), i64:$sz), (VSTLir v256f64:$vx, (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vst2d_vss v256f64:$vx, i64:$sy, i64:$sz), (VST2Drr v256f64:$vx, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vst2d_vss v256f64:$vx, (i64 simm7:$I), i64:$sz), (VST2Dir v256f64:$vx, (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vstu2d_vss v256f64:$vx, i64:$sy, i64:$sz), (VSTU2Drr v256f64:$vx, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vstu2d_vss v256f64:$vx, (i64 simm7:$I), i64:$sz), (VSTU2Dir v256f64:$vx, (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_vstl2d_vss v256f64:$vx, i64:$sy, i64:$sz), (VSTL2Drr v256f64:$vx, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vstl2d_vss v256f64:$vx, (i64 simm7:$I), i64:$sz), (VSTL2Dir v256f64:$vx, (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_pfchv i64:$sy, i64:$sz), (PFCHVr i64:$sy, i64:$sz)>;
def : Pat<(int_ve_pfchv (i64 simm7:$I), i64:$sz), (PFCHVi (i64 simm7:$I), i64:$sz)>;
def : Pat<(int_ve_lsv_vvss v256f64:$vx, i32:$sy, i64:$sz), (LSVr v256f64:$vx, i32:$sy, i64:$sz)>;
def : Pat<(int_ve_lvs_svs_u64 v256f64:$vx, i32:$sy), (LVSi64r v256f64:$vx, i32:$sy)>;
def : Pat<(int_ve_lvs_svs_f64 v256f64:$vx, i32:$sy), (LVSf64r v256f64:$vx, i32:$sy)>;
def : Pat<(int_ve_lvs_svs_f32 v256f64:$vx, i32:$sy), (LVSf32r v256f64:$vx, i32:$sy)>;
// def : Pat<(int_ve_lvm_mmss v4i64:$vmd, i64:$sy, i64:$sz), (LVMr v4i64:$vmd, i64:$sy, i64:$sz)>;
// def : Pat<(int_ve_lvm_mmss v4i64:$vmd, (i64 uimm6:$N), i64:$sz), (LVMi v4i64:$vmd, (i64 uimm6:$N), i64:$sz)>;
// def : Pat<(int_ve_lvm_MMss v8i64:$vmd, (i64 uimm6:$N), i64:$sz), (LVMpi v8i64:$vmd, (i64 uimm6:$N), i64:$sz)>;
// def : Pat<(int_ve_svm_sms v4i64:$vmz, i64:$sy), (SVMr v4i64:$vmz, i64:$sy)>;
// def : Pat<(int_ve_svm_sms v4i64:$vmz, (i64 uimm6:$N)), (SVMi v4i64:$vmz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_svm_sMs v8i64:$vmz, (i64 uimm6:$N)), (SVMpi v8i64:$vmz, (i64 uimm6:$N))>;
def : Pat<(int_ve_vbrd_vs_f64 f64:$sy), (VBRDf64r f64:$sy)>;
// def : Pat<(int_ve_vbrd_vsmv_f64 f64:$sy, v4i64:$vm, v256f64:$vd), (VBRDf64rm f64:$sy, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vbrd_vs_i64 i64:$sy), (VBRDr i64:$sy)>;
// def : Pat<(int_ve_vbrd_vsmv_i64 i64:$sy, v4i64:$vm, v256f64:$vd), (VBRDrm i64:$sy, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vbrd_vs_i64 (i64 simm7:$I)), (VBRDi (i64 simm7:$I))>;
// def : Pat<(int_ve_vbrd_vsmv_i64 (i64 simm7:$I), v4i64:$vm, v256f64:$vd), (VBRDim (i64 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vbrdu_vs_f32 f32:$sy), (VBRDf32r f32:$sy)>;
// def : Pat<(int_ve_vbrdu_vsmv_f32 f32:$sy, v4i64:$vm, v256f64:$vd), (VBRDf32rm f32:$sy, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vbrdl_vs_i32 i32:$sy), (VBRDi32r i32:$sy)>;
// def : Pat<(int_ve_vbrdl_vsmv_i32 i32:$sy, v4i64:$vm, v256f64:$vd), (VBRDi32rm i32:$sy, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vbrdl_vs_i32 (i32 simm7:$I)), (VBRDi32i (i32 simm7:$I))>;
// def : Pat<(int_ve_vbrdl_vsmv_i32 (i32 simm7:$I), v4i64:$vm, v256f64:$vd), (VBRDi32im (i32 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvbrd_vs_i64 i64:$sy), (VBRDpr i64:$sy)>;
// def : Pat<(int_ve_pvbrd_vsMv_i64 i64:$sy, v8i64:$vm, v256f64:$vd), (VBRDprm i64:$sy, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmv_vsv i32:$sy, v256f64:$vz), (VMVr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmv_vsv (i32 simm7:$I), v256f64:$vz), (VMVi (i32 simm7:$I), v256f64:$vz)>;
def : Pat<(int_ve_vaddul_vvv v256f64:$vy, v256f64:$vz), (VADDlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vaddul_vsv i64:$sy, v256f64:$vz), (VADDlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vaddul_vsv (i64 simm7:$I), v256f64:$vz), (VADDli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vaddul_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADDlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddul_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADDlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddul_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADDlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vadduw_vvv v256f64:$vy, v256f64:$vz), (VADDwv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vadduw_vsv i32:$sy, v256f64:$vz), (VADDwr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vadduw_vsv (i32 simm7:$I), v256f64:$vz), (VADDwi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vadduw_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADDwvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vadduw_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADDwrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vadduw_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADDwim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvaddu_vvv v256f64:$vy, v256f64:$vz), (VADDpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvaddu_vsv i64:$sy, v256f64:$vz), (VADDpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvaddu_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VADDpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvaddu_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VADDprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vaddswsx_vvv v256f64:$vy, v256f64:$vz), (VADSwsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vaddswsx_vsv i32:$sy, v256f64:$vz), (VADSwsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vaddswsx_vsv (i32 simm7:$I), v256f64:$vz), (VADSwsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vaddswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADSwsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADSwsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADSwsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vaddswzx_vvv v256f64:$vy, v256f64:$vz), (VADSwzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vaddswzx_vsv i32:$sy, v256f64:$vz), (VADSwzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vaddswzx_vsv (i32 simm7:$I), v256f64:$vz), (VADSwzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vaddswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADSwzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADSwzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADSwzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvadds_vvv v256f64:$vy, v256f64:$vz), (VADSpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvadds_vsv i64:$sy, v256f64:$vz), (VADSpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvadds_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VADSpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvadds_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VADSprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vaddsl_vvv v256f64:$vy, v256f64:$vz), (VADXlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vaddsl_vsv i64:$sy, v256f64:$vz), (VADXlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vaddsl_vsv (i64 simm7:$I), v256f64:$vz), (VADXli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vaddsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADXlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADXlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vaddsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VADXlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsubul_vvv v256f64:$vy, v256f64:$vz), (VSUBlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vsubul_vsv i64:$sy, v256f64:$vz), (VSUBlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vsubul_vsv (i64 simm7:$I), v256f64:$vz), (VSUBli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vsubul_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSUBlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubul_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSUBlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubul_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSUBlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsubuw_vvv v256f64:$vy, v256f64:$vz), (VSUBwv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vsubuw_vsv i32:$sy, v256f64:$vz), (VSUBwr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vsubuw_vsv (i32 simm7:$I), v256f64:$vz), (VSUBwi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vsubuw_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSUBwvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubuw_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSUBwrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubuw_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSUBwim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvsubu_vvv v256f64:$vy, v256f64:$vz), (VSUBpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvsubu_vsv i64:$sy, v256f64:$vz), (VSUBpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvsubu_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VSUBpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvsubu_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VSUBprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsubswsx_vvv v256f64:$vy, v256f64:$vz), (VSBSwsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vsubswsx_vsv i32:$sy, v256f64:$vz), (VSBSwsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vsubswsx_vsv (i32 simm7:$I), v256f64:$vz), (VSBSwsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vsubswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBSwsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBSwsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBSwsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsubswzx_vvv v256f64:$vy, v256f64:$vz), (VSBSwzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vsubswzx_vsv i32:$sy, v256f64:$vz), (VSBSwzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vsubswzx_vsv (i32 simm7:$I), v256f64:$vz), (VSBSwzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vsubswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBSwzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBSwzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBSwzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvsubs_vvv v256f64:$vy, v256f64:$vz), (VSBSpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvsubs_vsv i64:$sy, v256f64:$vz), (VSBSpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvsubs_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VSBSpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvsubs_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VSBSprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsubsl_vvv v256f64:$vy, v256f64:$vz), (VSBXlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vsubsl_vsv i64:$sy, v256f64:$vz), (VSBXlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vsubsl_vsv (i64 simm7:$I), v256f64:$vz), (VSBXli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vsubsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBXlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBXlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsubsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VSBXlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmulul_vvv v256f64:$vy, v256f64:$vz), (VMPYlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmulul_vsv i64:$sy, v256f64:$vz), (VMPYlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmulul_vsv (i64 simm7:$I), v256f64:$vz), (VMPYli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmulul_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPYlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulul_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPYlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulul_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPYlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmuluw_vvv v256f64:$vy, v256f64:$vz), (VMPYwv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmuluw_vsv i32:$sy, v256f64:$vz), (VMPYwr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmuluw_vsv (i32 simm7:$I), v256f64:$vz), (VMPYwi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmuluw_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPYwvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmuluw_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPYwrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmuluw_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPYwim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmulswsx_vvv v256f64:$vy, v256f64:$vz), (VMPSwsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmulswsx_vsv i32:$sy, v256f64:$vz), (VMPSwsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmulswsx_vsv (i32 simm7:$I), v256f64:$vz), (VMPSwsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmulswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPSwsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPSwsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPSwsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmulswzx_vvv v256f64:$vy, v256f64:$vz), (VMPSwzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmulswzx_vsv i32:$sy, v256f64:$vz), (VMPSwzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmulswzx_vsv (i32 simm7:$I), v256f64:$vz), (VMPSwzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmulswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPSwzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPSwzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPSwzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmulsl_vvv v256f64:$vy, v256f64:$vz), (VMPXlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmulsl_vsv i64:$sy, v256f64:$vz), (VMPXlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmulsl_vsv (i64 simm7:$I), v256f64:$vz), (VMPXli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmulsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPXlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPXlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmulsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VMPXlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmulslw_vvv v256f64:$vy, v256f64:$vz), (VMPDv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmulslw_vsv i32:$sy, v256f64:$vz), (VMPDr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmulslw_vsv (i32 simm7:$I), v256f64:$vz), (VMPDi (i32 simm7:$I), v256f64:$vz)>;
def : Pat<(int_ve_vdivul_vvv v256f64:$vy, v256f64:$vz), (VDIVlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vdivul_vsv i64:$sy, v256f64:$vz), (VDIVlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vdivul_vsv (i64 simm7:$I), v256f64:$vz), (VDIVli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vdivul_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDIVlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivul_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDIVlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivul_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDIVlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivuw_vvv v256f64:$vy, v256f64:$vz), (VDIVwv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vdivuw_vsv i32:$sy, v256f64:$vz), (VDIVwr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vdivuw_vsv (i32 simm7:$I), v256f64:$vz), (VDIVwi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vdivuw_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDIVwvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivuw_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDIVwrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivuw_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDIVwim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivul_vvs v256f64:$vy, i64:$sy), (VDIVlr2 v256f64:$vy, i64:$sy)>;
def : Pat<(int_ve_vdivul_vvs v256f64:$vy, (i64 simm7:$I)), (VDIVli2 v256f64:$vy, (i64 simm7:$I))>;
// def : Pat<(int_ve_vdivul_vvsmv v256f64:$vy, i64:$sy, v4i64:$vm, v256f64:$vd), (VDIVlrm2 v256f64:$vy, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivul_vvsmv v256f64:$vy, (i64 simm7:$I), v4i64:$vm, v256f64:$vd), (VDIVlim2 v256f64:$vy, (i64 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivuw_vvs v256f64:$vy, i32:$sy), (VDIVwr2 v256f64:$vy, i32:$sy)>;
def : Pat<(int_ve_vdivuw_vvs v256f64:$vy, (i32 simm7:$I)), (VDIVwi2 v256f64:$vy, (i32 simm7:$I))>;
// def : Pat<(int_ve_vdivuw_vvsmv v256f64:$vy, i32:$sy, v4i64:$vm, v256f64:$vd), (VDIVwrm2 v256f64:$vy, i32:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivuw_vvsmv v256f64:$vy, (i32 simm7:$I), v4i64:$vm, v256f64:$vd), (VDIVwim2 v256f64:$vy, (i32 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivswsx_vvv v256f64:$vy, v256f64:$vz), (VDVSwsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vdivswsx_vsv i32:$sy, v256f64:$vz), (VDVSwsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vdivswsx_vsv (i32 simm7:$I), v256f64:$vz), (VDVSwsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vdivswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVSwsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVSwsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVSwsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivswzx_vvv v256f64:$vy, v256f64:$vz), (VDVSwzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vdivswzx_vsv i32:$sy, v256f64:$vz), (VDVSwzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vdivswzx_vsv (i32 simm7:$I), v256f64:$vz), (VDVSwzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vdivswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVSwzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVSwzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVSwzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivswsx_vvs v256f64:$vy, i32:$sy), (VDVSwsxr2 v256f64:$vy, i32:$sy)>;
def : Pat<(int_ve_vdivswsx_vvs v256f64:$vy, (i32 simm7:$I)), (VDVSwsxi2 v256f64:$vy, (i32 simm7:$I))>;
// def : Pat<(int_ve_vdivswsx_vvsmv v256f64:$vy, i32:$sy, v4i64:$vm, v256f64:$vd), (VDVSwsxrm2 v256f64:$vy, i32:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivswsx_vvsmv v256f64:$vy, (i32 simm7:$I), v4i64:$vm, v256f64:$vd), (VDVSwsxim2 v256f64:$vy, (i32 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivswzx_vvs v256f64:$vy, i32:$sy), (VDVSwzxr2 v256f64:$vy, i32:$sy)>;
def : Pat<(int_ve_vdivswzx_vvs v256f64:$vy, (i32 simm7:$I)), (VDVSwzxi2 v256f64:$vy, (i32 simm7:$I))>;
// def : Pat<(int_ve_vdivswzx_vvsmv v256f64:$vy, i32:$sy, v4i64:$vm, v256f64:$vd), (VDVSwzxrm2 v256f64:$vy, i32:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivswzx_vvsmv v256f64:$vy, (i32 simm7:$I), v4i64:$vm, v256f64:$vd), (VDVSwzxim2 v256f64:$vy, (i32 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivsl_vvv v256f64:$vy, v256f64:$vz), (VDVXlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vdivsl_vsv i64:$sy, v256f64:$vz), (VDVXlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vdivsl_vsv (i64 simm7:$I), v256f64:$vz), (VDVXli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vdivsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVXlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVXlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VDVXlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vdivsl_vvs v256f64:$vy, i64:$sy), (VDVXlr2 v256f64:$vy, i64:$sy)>;
def : Pat<(int_ve_vdivsl_vvs v256f64:$vy, (i64 simm7:$I)), (VDVXli2 v256f64:$vy, (i64 simm7:$I))>;
// def : Pat<(int_ve_vdivsl_vvsmv v256f64:$vy, i64:$sy, v4i64:$vm, v256f64:$vd), (VDVXlrm2 v256f64:$vy, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vdivsl_vvsmv v256f64:$vy, (i64 simm7:$I), v4i64:$vm, v256f64:$vd), (VDVXlim2 v256f64:$vy, (i64 simm7:$I), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vcmpul_vvv v256f64:$vy, v256f64:$vz), (VCMPlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpul_vsv i64:$sy, v256f64:$vz), (VCMPlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpul_vsv (i64 simm7:$I), v256f64:$vz), (VCMPli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vcmpul_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMPlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpul_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMPlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpul_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMPlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vcmpuw_vvv v256f64:$vy, v256f64:$vz), (VCMPwv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpuw_vsv i32:$sy, v256f64:$vz), (VCMPwr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpuw_vsv (i32 simm7:$I), v256f64:$vz), (VCMPwi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vcmpuw_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMPwvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpuw_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMPwrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpuw_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMPwim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvcmpu_vvv v256f64:$vy, v256f64:$vz), (VCMPpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvcmpu_vsv i64:$sy, v256f64:$vz), (VCMPpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvcmpu_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCMPpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvcmpu_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCMPprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vcmpswsx_vvv v256f64:$vy, v256f64:$vz), (VCPSwsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpswsx_vsv i32:$sy, v256f64:$vz), (VCPSwsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpswsx_vsv (i32 simm7:$I), v256f64:$vz), (VCPSwsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vcmpswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPSwsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPSwsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPSwsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vcmpswzx_vvv v256f64:$vy, v256f64:$vz), (VCPSwzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpswzx_vsv i32:$sy, v256f64:$vz), (VCPSwzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpswzx_vsv (i32 simm7:$I), v256f64:$vz), (VCPSwzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vcmpswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPSwzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPSwzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPSwzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvcmps_vvv v256f64:$vy, v256f64:$vz), (VCPSpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvcmps_vsv i64:$sy, v256f64:$vz), (VCPSpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvcmps_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCPSpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvcmps_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCPSprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vcmpsl_vvv v256f64:$vy, v256f64:$vz), (VCPXlv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpsl_vsv i64:$sy, v256f64:$vz), (VCPXlr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vcmpsl_vsv (i64 simm7:$I), v256f64:$vz), (VCPXli (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vcmpsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPXlvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPXlrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vcmpsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPXlim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmaxswsx_vvv v256f64:$vy, v256f64:$vz), (VCMSawsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmaxswsx_vsv i32:$sy, v256f64:$vz), (VCMSawsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmaxswsx_vsv (i32 simm7:$I), v256f64:$vz), (VCMSawsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmaxswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSawsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmaxswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSawsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmaxswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSawsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmaxswzx_vvv v256f64:$vy, v256f64:$vz), (VCMSawzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmaxswzx_vsv i32:$sy, v256f64:$vz), (VCMSawzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmaxswzx_vsv (i32 simm7:$I), v256f64:$vz), (VCMSawzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmaxswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSawzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmaxswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSawzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmaxswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSawzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvmaxs_vvv v256f64:$vy, v256f64:$vz), (VCMSapv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvmaxs_vsv i64:$sy, v256f64:$vz), (VCMSapr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvmaxs_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCMSapvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvmaxs_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCMSaprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vminswsx_vvv v256f64:$vy, v256f64:$vz), (VCMSiwsxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vminswsx_vsv i32:$sy, v256f64:$vz), (VCMSiwsxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vminswsx_vsv (i32 simm7:$I), v256f64:$vz), (VCMSiwsxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vminswsx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSiwsxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vminswsx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSiwsxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vminswsx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSiwsxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vminswzx_vvv v256f64:$vy, v256f64:$vz), (VCMSiwzxv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vminswzx_vsv i32:$sy, v256f64:$vz), (VCMSiwzxr i32:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vminswzx_vsv (i32 simm7:$I), v256f64:$vz), (VCMSiwzxi (i32 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vminswzx_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSiwzxvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vminswzx_vsvmv i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSiwzxrm i32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vminswzx_vsvmv (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMSiwzxim (i32 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvmins_vvv v256f64:$vy, v256f64:$vz), (VCMSipv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvmins_vsv i64:$sy, v256f64:$vz), (VCMSipr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvmins_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCMSipvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvmins_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VCMSiprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vmaxsl_vvv v256f64:$vy, v256f64:$vz), (VCMXalv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vmaxsl_vsv i64:$sy, v256f64:$vz), (VCMXalr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vmaxsl_vsv (i64 simm7:$I), v256f64:$vz), (VCMXali (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vmaxsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMXalvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmaxsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMXalrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vmaxsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMXalim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vminsl_vvv v256f64:$vy, v256f64:$vz), (VCMXilv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vminsl_vsv i64:$sy, v256f64:$vz), (VCMXilr i64:$sy, v256f64:$vz)>;
def : Pat<(int_ve_vminsl_vsv (i64 simm7:$I), v256f64:$vz), (VCMXili (i64 simm7:$I), v256f64:$vz)>;
// def : Pat<(int_ve_vminsl_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMXilvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vminsl_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMXilrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vminsl_vsvmv (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCMXilim (i64 simm7:$I), v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vand_vvv v256f64:$vy, v256f64:$vz), (VANDv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vand_vsv i64:$sy, v256f64:$vz), (VANDr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vand_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VANDvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vand_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VANDrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvand_vvv v256f64:$vy, v256f64:$vz), (VANDpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvand_vsv i64:$sy, v256f64:$vz), (VANDpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvand_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VANDpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvand_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VANDprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vor_vvv v256f64:$vy, v256f64:$vz), (VORv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vor_vsv i64:$sy, v256f64:$vz), (VORr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vor_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VORvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vor_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VORrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvor_vvv v256f64:$vy, v256f64:$vz), (VORpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvor_vsv i64:$sy, v256f64:$vz), (VORpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvor_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VORpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvor_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VORprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vxor_vvv v256f64:$vy, v256f64:$vz), (VXORv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vxor_vsv i64:$sy, v256f64:$vz), (VXORr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vxor_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VXORvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vxor_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VXORrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvxor_vvv v256f64:$vy, v256f64:$vz), (VXORpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvxor_vsv i64:$sy, v256f64:$vz), (VXORpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvxor_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VXORpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvxor_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VXORprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_veqv_vvv v256f64:$vy, v256f64:$vz), (VEQVv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_veqv_vsv i64:$sy, v256f64:$vz), (VEQVr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_veqv_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VEQVvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_veqv_vsvmv i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VEQVrm i64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pveqv_vvv v256f64:$vy, v256f64:$vz), (VEQVpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pveqv_vsv i64:$sy, v256f64:$vz), (VEQVpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pveqv_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VEQVpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pveqv_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VEQVprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vseq_v ), (VSEQv )>;
def : Pat<(int_ve_pvseqlo_v ), (VSEQlv )>;
def : Pat<(int_ve_pvsequp_v ), (VSEQuv )>;
def : Pat<(int_ve_pvseq_v ), (VSEQpv )>;
def : Pat<(int_ve_vsll_vvv v256f64:$vz, v256f64:$vy), (VSLLv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_vsll_vvs v256f64:$vz, i64:$sy), (VSLLr2 v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vsll_vvs v256f64:$vz, (i64 uimm6:$N)), (VSLLi2 v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vsll_vvvmv v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd), (VSLLvm v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsll_vvsmv v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd), (VSLLrm2 v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsll_vvsmv v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd), (VSLLim2 v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvsll_vvv v256f64:$vz, v256f64:$vy), (VSLLpv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_pvsll_vvs v256f64:$vz, i64:$sy), (VSLLpr2 v256f64:$vz, i64:$sy)>;
// def : Pat<(int_ve_pvsll_vvvMv v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd), (VSLLpvm v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvsll_vvsMv v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd), (VSLLprm2 v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsrl_vvv v256f64:$vz, v256f64:$vy), (VSRLv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_vsrl_vvs v256f64:$vz, i64:$sy), (VSRLr2 v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vsrl_vvs v256f64:$vz, (i64 uimm6:$N)), (VSRLi2 v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vsrl_vvvmv v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd), (VSRLvm v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsrl_vvsmv v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd), (VSRLrm2 v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsrl_vvsmv v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd), (VSRLim2 v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvsrl_vvv v256f64:$vz, v256f64:$vy), (VSRLpv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_pvsrl_vvs v256f64:$vz, i64:$sy), (VSRLpr2 v256f64:$vz, i64:$sy)>;
// def : Pat<(int_ve_pvsrl_vvvMv v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd), (VSRLpvm v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvsrl_vvsMv v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd), (VSRLprm2 v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vslaw_vvv v256f64:$vz, v256f64:$vy), (VSLAv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_vslaw_vvs v256f64:$vz, i64:$sy), (VSLAr2 v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vslaw_vvs v256f64:$vz, (i64 uimm6:$N)), (VSLAi2 v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vslaw_vvvmv v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd), (VSLAvm v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vslaw_vvsmv v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd), (VSLArm2 v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vslaw_vvsmv v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd), (VSLAim2 v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvsla_vvv v256f64:$vz, v256f64:$vy), (VSLApv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_pvsla_vvs v256f64:$vz, i64:$sy), (VSLApr2 v256f64:$vz, i64:$sy)>;
// def : Pat<(int_ve_pvsla_vvvMv v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd), (VSLApvm v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvsla_vvsMv v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd), (VSLAprm2 v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vslal_vvv v256f64:$vz, v256f64:$vy), (VSLAXv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_vslal_vvs v256f64:$vz, i64:$sy), (VSLAXr2 v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vslal_vvs v256f64:$vz, (i64 uimm6:$N)), (VSLAXi2 v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vslal_vvvmv v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd), (VSLAXvm v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vslal_vvsmv v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd), (VSLAXrm2 v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vslal_vvsmv v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd), (VSLAXim2 v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsraw_vvv v256f64:$vz, v256f64:$vy), (VSRAv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_vsraw_vvs v256f64:$vz, i64:$sy), (VSRAr2 v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vsraw_vvs v256f64:$vz, (i64 uimm6:$N)), (VSRAi2 v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vsraw_vvvmv v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd), (VSRAvm v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsraw_vvsmv v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd), (VSRArm2 v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsraw_vvsmv v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd), (VSRAim2 v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvsra_vvv v256f64:$vz, v256f64:$vy), (VSRApv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_pvsra_vvs v256f64:$vz, i64:$sy), (VSRApr2 v256f64:$vz, i64:$sy)>;
// def : Pat<(int_ve_pvsra_vvvMv v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd), (VSRApvm v256f64:$vz, v256f64:$vy, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvsra_vvsMv v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd), (VSRAprm2 v256f64:$vz, i64:$sy, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsral_vvv v256f64:$vz, v256f64:$vy), (VSRAXv v256f64:$vz, v256f64:$vy)>;
def : Pat<(int_ve_vsral_vvs v256f64:$vz, i64:$sy), (VSRAXr2 v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vsral_vvs v256f64:$vz, (i64 uimm6:$N)), (VSRAXi2 v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vsral_vvvmv v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd), (VSRAXvm v256f64:$vz, v256f64:$vy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsral_vvsmv v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd), (VSRAXrm2 v256f64:$vz, i64:$sy, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsral_vvsmv v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd), (VSRAXim2 v256f64:$vz, (i64 uimm6:$N), v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vsfa_vvss v256f64:$vz, i64:$sy, i64:$sz), (VSFAr v256f64:$vz, i64:$sy, i64:$sz)>;
def : Pat<(int_ve_vsfa_vvss v256f64:$vz, (i64 simm7:$I), i64:$sz), (VSFAi v256f64:$vz, (i64 simm7:$I), i64:$sz)>;
// def : Pat<(int_ve_vsfa_vvssmv v256f64:$vz, i64:$sy, i64:$sz, v4i64:$vm, v256f64:$vd), (VSFArm v256f64:$vz, i64:$sy, i64:$sz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vsfa_vvssmv v256f64:$vz, (i64 simm7:$I), i64:$sz, v4i64:$vm, v256f64:$vd), (VSFAim v256f64:$vz, (i64 simm7:$I), i64:$sz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfaddd_vvv v256f64:$vy, v256f64:$vz), (VFADdv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfaddd_vsv f64:$sy, v256f64:$vz), (VFADdr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfaddd_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFADdvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfaddd_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFADdrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfadds_vvv v256f64:$vy, v256f64:$vz), (VFADsv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfadds_vsv f32:$sy, v256f64:$vz), (VFADsr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfadds_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFADsvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfadds_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFADsrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfadd_vvv v256f64:$vy, v256f64:$vz), (VFADpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvfadd_vsv i64:$sy, v256f64:$vz), (VFADpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvfadd_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFADpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfadd_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFADprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfsubd_vvv v256f64:$vy, v256f64:$vz), (VFSBdv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfsubd_vsv f64:$sy, v256f64:$vz), (VFSBdr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfsubd_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFSBdvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfsubd_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFSBdrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfsubs_vvv v256f64:$vy, v256f64:$vz), (VFSBsv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfsubs_vsv f32:$sy, v256f64:$vz), (VFSBsr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfsubs_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFSBsvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfsubs_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFSBsrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfsub_vvv v256f64:$vy, v256f64:$vz), (VFSBpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvfsub_vsv i64:$sy, v256f64:$vz), (VFSBpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvfsub_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFSBpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfsub_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFSBprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmuld_vvv v256f64:$vy, v256f64:$vz), (VFMPdv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfmuld_vsv f64:$sy, v256f64:$vz), (VFMPdr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfmuld_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFMPdvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmuld_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFMPdrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmuls_vvv v256f64:$vy, v256f64:$vz), (VFMPsv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfmuls_vsv f32:$sy, v256f64:$vz), (VFMPsr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfmuls_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFMPsvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmuls_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFMPsrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfmul_vvv v256f64:$vy, v256f64:$vz), (VFMPpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvfmul_vsv i64:$sy, v256f64:$vz), (VFMPpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvfmul_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFMPpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmul_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFMPprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfdivd_vvv v256f64:$vy, v256f64:$vz), (VFDVdv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfdivd_vsv f64:$sy, v256f64:$vz), (VFDVdr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfdivd_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFDVdvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfdivd_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFDVdrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfdivs_vvv v256f64:$vy, v256f64:$vz), (VFDVsv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfdivs_vsv f32:$sy, v256f64:$vz), (VFDVsr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfdivs_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFDVsvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfdivs_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFDVsrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfsqrtd_vv v256f64:$vy), (VFSQRTdv v256f64:$vy)>;
def : Pat<(int_ve_vfsqrts_vv v256f64:$vy), (VFSQRTsv v256f64:$vy)>;
def : Pat<(int_ve_vfcmpd_vvv v256f64:$vy, v256f64:$vz), (VFCPdv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfcmpd_vsv f64:$sy, v256f64:$vz), (VFCPdr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfcmpd_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCPdvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfcmpd_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCPdrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfcmps_vvv v256f64:$vy, v256f64:$vz), (VFCPsv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfcmps_vsv f32:$sy, v256f64:$vz), (VFCPsr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfcmps_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCPsvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfcmps_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCPsrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfcmp_vvv v256f64:$vy, v256f64:$vz), (VFCPpv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvfcmp_vsv i64:$sy, v256f64:$vz), (VFCPpr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvfcmp_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFCPpvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfcmp_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFCPprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmaxd_vvv v256f64:$vy, v256f64:$vz), (VFCMadv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfmaxd_vsv f64:$sy, v256f64:$vz), (VFCMadr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfmaxd_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMadvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmaxd_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMadrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmaxs_vvv v256f64:$vy, v256f64:$vz), (VFCMasv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfmaxs_vsv f32:$sy, v256f64:$vz), (VFCMasr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfmaxs_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMasvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmaxs_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMasrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfmax_vvv v256f64:$vy, v256f64:$vz), (VFCMapv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvfmax_vsv i64:$sy, v256f64:$vz), (VFCMapr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvfmax_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFCMapvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmax_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFCMaprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmind_vvv v256f64:$vy, v256f64:$vz), (VFCMidv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfmind_vsv f64:$sy, v256f64:$vz), (VFCMidr f64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfmind_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMidvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmind_vsvmv f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMidrm f64:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmins_vvv v256f64:$vy, v256f64:$vz), (VFCMisv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_vfmins_vsv f32:$sy, v256f64:$vz), (VFCMisr f32:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_vfmins_vvvmv v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMisvm v256f64:$vy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmins_vsvmv f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd), (VFCMisrm f32:$sy, v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfmin_vvv v256f64:$vy, v256f64:$vz), (VFCMipv v256f64:$vy, v256f64:$vz)>;
def : Pat<(int_ve_pvfmin_vsv i64:$sy, v256f64:$vz), (VFCMipr i64:$sy, v256f64:$vz)>;
// def : Pat<(int_ve_pvfmin_vvvMv v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFCMipvm v256f64:$vy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmin_vsvMv i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd), (VFCMiprm i64:$sy, v256f64:$vz, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmadd_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFMADdv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmadd_vsvv f64:$sy, v256f64:$vz, v256f64:$vw), (VFMADdr f64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmadd_vvsv v256f64:$vy, f64:$sy, v256f64:$vw), (VFMADdr2 v256f64:$vy, f64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfmadd_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMADdvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmadd_vsvvmv f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMADdrm f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmadd_vvsvmv v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMADdr2m v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmads_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFMADsv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmads_vsvv f32:$sy, v256f64:$vz, v256f64:$vw), (VFMADsr f32:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmads_vvsv v256f64:$vy, f32:$sy, v256f64:$vw), (VFMADsr2 v256f64:$vy, f32:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfmads_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMADsvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmads_vsvvmv f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMADsrm f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmads_vvsvmv v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMADsr2m v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfmad_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFMADpv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfmad_vsvv i64:$sy, v256f64:$vz, v256f64:$vw), (VFMADpr i64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfmad_vvsv v256f64:$vy, i64:$sy, v256f64:$vw), (VFMADpr2 v256f64:$vy, i64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_pvfmad_vvvvMv v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFMADpvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmad_vsvvMv i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFMADprm i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmad_vvsvMv v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFMADpr2m v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmsbd_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFMSBdv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmsbd_vsvv f64:$sy, v256f64:$vz, v256f64:$vw), (VFMSBdr f64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmsbd_vvsv v256f64:$vy, f64:$sy, v256f64:$vw), (VFMSBdr2 v256f64:$vy, f64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfmsbd_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMSBdvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmsbd_vsvvmv f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMSBdrm f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmsbd_vvsvmv v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMSBdr2m v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfmsbs_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFMSBsv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmsbs_vsvv f32:$sy, v256f64:$vz, v256f64:$vw), (VFMSBsr f32:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfmsbs_vvsv v256f64:$vy, f32:$sy, v256f64:$vw), (VFMSBsr2 v256f64:$vy, f32:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfmsbs_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMSBsvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmsbs_vsvvmv f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMSBsrm f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmsbs_vvsvmv v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFMSBsr2m v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfmsb_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFMSBpv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfmsb_vsvv i64:$sy, v256f64:$vz, v256f64:$vw), (VFMSBpr i64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfmsb_vvsv v256f64:$vy, i64:$sy, v256f64:$vw), (VFMSBpr2 v256f64:$vy, i64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_pvfmsb_vvvvMv v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFMSBpvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmsb_vsvvMv i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFMSBprm i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfmsb_vvsvMv v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFMSBpr2m v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfnmadd_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFNMADdv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmadd_vsvv f64:$sy, v256f64:$vz, v256f64:$vw), (VFNMADdr f64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmadd_vvsv v256f64:$vy, f64:$sy, v256f64:$vw), (VFNMADdr2 v256f64:$vy, f64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfnmadd_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMADdvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmadd_vsvvmv f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMADdrm f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmadd_vvsvmv v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMADdr2m v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfnmads_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFNMADsv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmads_vsvv f32:$sy, v256f64:$vz, v256f64:$vw), (VFNMADsr f32:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmads_vvsv v256f64:$vy, f32:$sy, v256f64:$vw), (VFNMADsr2 v256f64:$vy, f32:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfnmads_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMADsvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmads_vsvvmv f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMADsrm f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmads_vvsvmv v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMADsr2m v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfnmad_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFNMADpv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfnmad_vsvv i64:$sy, v256f64:$vz, v256f64:$vw), (VFNMADpr i64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfnmad_vvsv v256f64:$vy, i64:$sy, v256f64:$vw), (VFNMADpr2 v256f64:$vy, i64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_pvfnmad_vvvvMv v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFNMADpvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfnmad_vsvvMv i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFNMADprm i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfnmad_vvsvMv v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFNMADpr2m v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfnmsbd_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFNMSBdv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmsbd_vsvv f64:$sy, v256f64:$vz, v256f64:$vw), (VFNMSBdr f64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmsbd_vvsv v256f64:$vy, f64:$sy, v256f64:$vw), (VFNMSBdr2 v256f64:$vy, f64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfnmsbd_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMSBdvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmsbd_vsvvmv f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMSBdrm f64:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmsbd_vvsvmv v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMSBdr2m v256f64:$vy, f64:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vfnmsbs_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFNMSBsv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmsbs_vsvv f32:$sy, v256f64:$vz, v256f64:$vw), (VFNMSBsr f32:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_vfnmsbs_vvsv v256f64:$vy, f32:$sy, v256f64:$vw), (VFNMSBsr2 v256f64:$vy, f32:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_vfnmsbs_vvvvmv v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMSBsvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmsbs_vsvvmv f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMSBsrm f32:$sy, v256f64:$vz, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfnmsbs_vvsvmv v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd), (VFNMSBsr2m v256f64:$vy, f32:$sy, v256f64:$vw, v4i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_pvfnmsb_vvvv v256f64:$vy, v256f64:$vz, v256f64:$vw), (VFNMSBpv v256f64:$vy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfnmsb_vsvv i64:$sy, v256f64:$vz, v256f64:$vw), (VFNMSBpr i64:$sy, v256f64:$vz, v256f64:$vw)>;
def : Pat<(int_ve_pvfnmsb_vvsv v256f64:$vy, i64:$sy, v256f64:$vw), (VFNMSBpr2 v256f64:$vy, i64:$sy, v256f64:$vw)>;
// def : Pat<(int_ve_pvfnmsb_vvvvMv v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFNMSBpvm v256f64:$vy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfnmsb_vsvvMv i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFNMSBprm i64:$sy, v256f64:$vz, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_pvfnmsb_vvsvMv v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd), (VFNMSBpr2m v256f64:$vy, i64:$sy, v256f64:$vw, v8i64:$vm, v256f64:$vd)>;
def : Pat<(int_ve_vrcpd_vv v256f64:$vy), (VRCPdv v256f64:$vy)>;
def : Pat<(int_ve_vrcps_vv v256f64:$vy), (VRCPsv v256f64:$vy)>;
def : Pat<(int_ve_pvrcp_vv v256f64:$vy), (VRCPpv v256f64:$vy)>;
def : Pat<(int_ve_vrsqrtd_vv v256f64:$vy), (VRSQRTdv v256f64:$vy)>;
def : Pat<(int_ve_vrsqrts_vv v256f64:$vy), (VRSQRTsv v256f64:$vy)>;
def : Pat<(int_ve_pvrsqrt_vv v256f64:$vy), (VRSQRTpv v256f64:$vy)>;
def : Pat<(int_ve_vcvtwdsx_vv v256f64:$vy), (VFIXdsxv v256f64:$vy)>;
def : Pat<(int_ve_vcvtwdzx_vv v256f64:$vy), (VFIXdzxv v256f64:$vy)>;
def : Pat<(int_ve_vcvtwssx_vv v256f64:$vy), (VFIXssxv v256f64:$vy)>;
def : Pat<(int_ve_vcvtwszx_vv v256f64:$vy), (VFIXszxv v256f64:$vy)>;
def : Pat<(int_ve_pvcvtws_vv v256f64:$vy), (VFIXpv v256f64:$vy)>;
def : Pat<(int_ve_vcvtld_vv v256f64:$vy), (VFIXXv v256f64:$vy)>;
def : Pat<(int_ve_vcvtdw_vv v256f64:$vy), (VFLTdv v256f64:$vy)>;
def : Pat<(int_ve_vcvtsw_vv v256f64:$vy), (VFLTsv v256f64:$vy)>;
def : Pat<(int_ve_pvcvtsw_vv v256f64:$vy), (VFLTpv v256f64:$vy)>;
def : Pat<(int_ve_vcvtdl_vv v256f64:$vy), (VFLTXv v256f64:$vy)>;
def : Pat<(int_ve_vcvtds_vv v256f64:$vy), (VCVDv v256f64:$vy)>;
def : Pat<(int_ve_vcvtsd_vv v256f64:$vy), (VCVSv v256f64:$vy)>;
// def : Pat<(int_ve_vmrg_vvvm v256f64:$vy, v256f64:$vz, v4i64:$vm), (VMRGvm v256f64:$vy, v256f64:$vz, v4i64:$vm)>;
// def : Pat<(int_ve_vmrgw_vvvM v256f64:$vy, v256f64:$vz, v8i64:$vm), (VMRGpvm v256f64:$vy, v256f64:$vz, v8i64:$vm)>;
def : Pat<(int_ve_vshf_vvvs v256f64:$vy, v256f64:$vz, i64:$sy), (VSHFr v256f64:$vy, v256f64:$vz, i64:$sy)>;
def : Pat<(int_ve_vshf_vvvs v256f64:$vy, v256f64:$vz, (i64 uimm6:$N)), (VSHFi v256f64:$vy, v256f64:$vz, (i64 uimm6:$N))>;
// def : Pat<(int_ve_vcp_vvmv v256f64:$vz, v4i64:$vm, v256f64:$vd), (VCPvm v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vex_vvmv v256f64:$vz, v4i64:$vm, v256f64:$vd), (VEXvm v256f64:$vz, v4i64:$vm, v256f64:$vd)>;
// def : Pat<(int_ve_vfmkl_mcv (i32 uimm6:$cc), v256f64:$vz), (VFMKv (i32 uimm6:$cc), v256f64:$vz)>;
// def : Pat<(int_ve_vfmkl_mcvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm), (VFMKvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm)>;
// def : Pat<(int_ve_vfmkat_m ), (VFMKat )>;
// def : Pat<(int_ve_vfmkaf_m ), (VFMKaf )>;
// def : Pat<(int_ve_pvfmkat_M ), (VFMKpat )>;
// def : Pat<(int_ve_pvfmkaf_M ), (VFMKpaf )>;
// def : Pat<(int_ve_vfmkw_mcv (i32 uimm6:$cc), v256f64:$vz), (VFMSv (i32 uimm6:$cc), v256f64:$vz)>;
// def : Pat<(int_ve_vfmkw_mcvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm), (VFMSvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm)>;
// def : Pat<(int_ve_pvfmkw_Mcv (i32 uimm6:$cc), v256f64:$vz), (VFMSpv (i32 uimm6:$cc), v256f64:$vz)>;
// def : Pat<(int_ve_pvfmkw_McvM (i32 uimm6:$cc), v256f64:$vz, v8i64:$vm), (VFMSpvm (i32 uimm6:$cc), v256f64:$vz, v8i64:$vm)>;
// def : Pat<(int_ve_vfmkd_mcv (i32 uimm6:$cc), v256f64:$vz), (VFMFdv (i32 uimm6:$cc), v256f64:$vz)>;
// def : Pat<(int_ve_vfmkd_mcvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm), (VFMFdvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm)>;
// def : Pat<(int_ve_vfmks_mcv (i32 uimm6:$cc), v256f64:$vz), (VFMFsv (i32 uimm6:$cc), v256f64:$vz)>;
// def : Pat<(int_ve_vfmks_mcvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm), (VFMFsvm (i32 uimm6:$cc), v256f64:$vz, v4i64:$vm)>;
// def : Pat<(int_ve_pvfmks_Mcv (i32 uimm6:$cc), v256f64:$vz), (VFMFpv (i32 uimm6:$cc), v256f64:$vz)>;
// def : Pat<(int_ve_pvfmks_McvM (i32 uimm6:$cc), v256f64:$vz, v8i64:$vm), (VFMFpvm (i32 uimm6:$cc), v256f64:$vz, v8i64:$vm)>;
def : Pat<(int_ve_vsumwsx_vv v256f64:$vy), (VSUMSsxv v256f64:$vy)>;
def : Pat<(int_ve_vsumwzx_vv v256f64:$vy), (VSUMSzxv v256f64:$vy)>;
def : Pat<(int_ve_vsuml_vv v256f64:$vy), (VSUMXv v256f64:$vy)>;
def : Pat<(int_ve_vfsumd_vv v256f64:$vy), (VFSUMdv v256f64:$vy)>;
def : Pat<(int_ve_vfsums_vv v256f64:$vy), (VFSUMsv v256f64:$vy)>;
def : Pat<(int_ve_vrmaxswfstsx_vv v256f64:$vy), (VMAXSafsxv v256f64:$vy)>;
def : Pat<(int_ve_vrmaxswlstsx_vv v256f64:$vy), (VMAXSalsxv v256f64:$vy)>;
def : Pat<(int_ve_vrmaxswfstzx_vv v256f64:$vy), (VMAXSafzxv v256f64:$vy)>;
def : Pat<(int_ve_vrmaxswlstzx_vv v256f64:$vy), (VMAXSalzxv v256f64:$vy)>;
def : Pat<(int_ve_vrminswfstsx_vv v256f64:$vy), (VMAXSifsxv v256f64:$vy)>;
def : Pat<(int_ve_vrminswlstsx_vv v256f64:$vy), (VMAXSilsxv v256f64:$vy)>;
def : Pat<(int_ve_vrminswfstzx_vv v256f64:$vy), (VMAXSifzxv v256f64:$vy)>;
def : Pat<(int_ve_vrminswlstzx_vv v256f64:$vy), (VMAXSilzxv v256f64:$vy)>;
def : Pat<(int_ve_vrmaxslfst_vv v256f64:$vy), (VMAXXafv v256f64:$vy)>;
def : Pat<(int_ve_vrmaxsllst_vv v256f64:$vy), (VMAXXalv v256f64:$vy)>;
def : Pat<(int_ve_vrminslfst_vv v256f64:$vy), (VMAXXifv v256f64:$vy)>;
def : Pat<(int_ve_vrminsllst_vv v256f64:$vy), (VMAXXilv v256f64:$vy)>;
def : Pat<(int_ve_vfrmaxdfst_vv v256f64:$vy), (VFMAXadfv v256f64:$vy)>;
def : Pat<(int_ve_vfrmaxdlst_vv v256f64:$vy), (VFMAXadlv v256f64:$vy)>;
def : Pat<(int_ve_vfrmaxsfst_vv v256f64:$vy), (VFMAXasfv v256f64:$vy)>;
def : Pat<(int_ve_vfrmaxslst_vv v256f64:$vy), (VFMAXaslv v256f64:$vy)>;
def : Pat<(int_ve_vfrmindfst_vv v256f64:$vy), (VFMAXidfv v256f64:$vy)>;
def : Pat<(int_ve_vfrmindlst_vv v256f64:$vy), (VFMAXidlv v256f64:$vy)>;
def : Pat<(int_ve_vfrminsfst_vv v256f64:$vy), (VFMAXisfv v256f64:$vy)>;
def : Pat<(int_ve_vfrminslst_vv v256f64:$vy), (VFMAXislv v256f64:$vy)>;
def : Pat<(int_ve_vgt_vv v256f64:$vy), (VGTv v256f64:$vy)>;
// def : Pat<(int_ve_vgt_vvm v256f64:$vy, v4i64:$vm), (VGTvm v256f64:$vy, v4i64:$vm)>;
def : Pat<(int_ve_vgtu_vv v256f64:$vy), (VGTUv v256f64:$vy)>;
// def : Pat<(int_ve_vgtu_vvm v256f64:$vy, v4i64:$vm), (VGTUvm v256f64:$vy, v4i64:$vm)>;
def : Pat<(int_ve_vgtlsx_vv v256f64:$vy), (VGTLsxv v256f64:$vy)>;
// def : Pat<(int_ve_vgtlsx_vvm v256f64:$vy, v4i64:$vm), (VGTLsxvm v256f64:$vy, v4i64:$vm)>;
def : Pat<(int_ve_vgtlzx_vv v256f64:$vy), (VGTLzxv v256f64:$vy)>;
// def : Pat<(int_ve_vgtlzx_vvm v256f64:$vy, v4i64:$vm), (VGTLzxvm v256f64:$vy, v4i64:$vm)>;
def : Pat<(int_ve_vsc_vv v256f64:$vx, v256f64:$vy), (VSCv v256f64:$vx, v256f64:$vy)>;
// def : Pat<(int_ve_vsc_vvm v256f64:$vx, v256f64:$vy, v4i64:$vm), (VSCvm v256f64:$vx, v256f64:$vy, v4i64:$vm)>;
def : Pat<(int_ve_vscu_vv v256f64:$vx, v256f64:$vy), (VSCUv v256f64:$vx, v256f64:$vy)>;
// def : Pat<(int_ve_vscu_vvm v256f64:$vx, v256f64:$vy, v4i64:$vm), (VSCUvm v256f64:$vx, v256f64:$vy, v4i64:$vm)>;
def : Pat<(int_ve_vscl_vv v256f64:$vx, v256f64:$vy), (VSCLv v256f64:$vx, v256f64:$vy)>;
// def : Pat<(int_ve_vscl_vvm v256f64:$vx, v256f64:$vy, v4i64:$vm), (VSCLvm v256f64:$vx, v256f64:$vy, v4i64:$vm)>;
// def : Pat<(int_ve_andm_mmm v4i64:$vmy, v4i64:$vmz), (ANDM v4i64:$vmy, v4i64:$vmz)>;
// def : Pat<(int_ve_andm_MMM v8i64:$vmy, v8i64:$vmz), (ANDMp v8i64:$vmy, v8i64:$vmz)>;
// def : Pat<(int_ve_orm_mmm v4i64:$vmy, v4i64:$vmz), (ORM v4i64:$vmy, v4i64:$vmz)>;
// def : Pat<(int_ve_orm_MMM v8i64:$vmy, v8i64:$vmz), (ORMp v8i64:$vmy, v8i64:$vmz)>;
// def : Pat<(int_ve_xorm_mmm v4i64:$vmy, v4i64:$vmz), (XORM v4i64:$vmy, v4i64:$vmz)>;
// def : Pat<(int_ve_xorm_MMM v8i64:$vmy, v8i64:$vmz), (XORMp v8i64:$vmy, v8i64:$vmz)>;
// def : Pat<(int_ve_eqvm_mmm v4i64:$vmy, v4i64:$vmz), (EQVM v4i64:$vmy, v4i64:$vmz)>;
// def : Pat<(int_ve_eqvm_MMM v8i64:$vmy, v8i64:$vmz), (EQVMp v8i64:$vmy, v8i64:$vmz)>;
// def : Pat<(int_ve_nndm_mmm v4i64:$vmy, v4i64:$vmz), (NNDM v4i64:$vmy, v4i64:$vmz)>;
// def : Pat<(int_ve_nndm_MMM v8i64:$vmy, v8i64:$vmz), (NNDMp v8i64:$vmy, v8i64:$vmz)>;
// def : Pat<(int_ve_negm_mm v4i64:$vmy), (NEGM v4i64:$vmy)>;
// def : Pat<(int_ve_negm_MM v8i64:$vmy), (NEGMp v8i64:$vmy)>;
// def : Pat<(int_ve_pcvm_sm v4i64:$vmy), (PCVM v4i64:$vmy)>;
// def : Pat<(int_ve_lzvm_sm v4i64:$vmy), (LZVM v4i64:$vmy)>;
// def : Pat<(int_ve_tovm_sm v4i64:$vmy), (TOVM v4i64:$vmy)>;
